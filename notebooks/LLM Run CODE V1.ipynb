{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading enhanced taxonomy data from C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\enhanced_military_skills_taxonomy.json...\n",
      "Data loaded successfully!\n",
      "Loaded data with 3 AFSC categories\n",
      "Using the LLM-optimized structure as the base data\n",
      "Created enhanced sample without Warrant category (2 categories)\n",
      "  - Enlisted: 15 AFSCs\n",
      "  - Officer: 15 AFSCs\n",
      "Created prompt with 76429 characters\n",
      "Prompt saved to C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\enhanced_taxonomy_prompt.txt\n",
      "\n",
      "===== GENERATION OPTIONS =====\n",
      "1: Use API directly (requires API keys)\n",
      "2: Create prompt for manual submission to web interfaces\n",
      "\n",
      "===== API KEY INPUT =====\n",
      "Calling Claude API with claude-3-5-sonnet-20240620 (attempt 1/3)...\n",
      "Taxonomy saved to C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\military_skills_taxonomy_claude_3_5_sonnet_20250403-001643.txt\n",
      "Claude taxonomy generated and saved to C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\military_skills_taxonomy_claude_3_5_sonnet_20250403-001643.txt\n",
      "Calling OpenAI API using gpt-4-turbo...\n",
      "Taxonomy saved to C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\military_skills_taxonomy_gpt_4_turbo_enhanced_20250403-001752.txt\n",
      "Enhanced gpt-4-turbo taxonomy generated and saved to C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\military_skills_taxonomy_gpt_4_turbo_enhanced_20250403-001752.txt\n",
      "\n",
      "Taxonomy Generation Summary:\n",
      "===========================\n",
      "✓ CLAUDE taxonomy generated\n",
      "✓ OPENAI taxonomy generated\n"
     ]
    }
   ],
   "source": [
    "# Finalized Military Skills Taxonomy Generator\n",
    "# Uses claude-3-5-sonnet-20240620 model and a sample size of 15 AFSCs per category\n",
    "# If you're reading this you'll have to change the paths to the files for your system. Additionally, you will need to add your API keys for Anthropic and OpenAI, but the code will prompt you for them.\n",
    "# This code is designed to be run in a Python 3 environment with the requests library installed.\n",
    "# Addtionally there is a V2 of this code that runs over a larger sample size of 25-30 AFSCs per category. I would recommend using that version if you have the time and resources to do so. It is located in the same directory as this code.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Define file paths\n",
    "ENHANCED_TAXONOMY_PATH = r\"C:\"\n",
    "OUTPUT_DIR = r\"C:\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Load and examine the enhanced taxonomy file\n",
    "def load_taxonomy_data(file_path):\n",
    "    print(f\"Loading enhanced taxonomy data from {file_path}...\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(\"Data loaded successfully!\")\n",
    "    return data\n",
    "\n",
    "# 2. Create a representative sample of the data without Warrant category\n",
    "def create_representative_sample(data, sample_size=15, exclude_categories=[\"Warrant\"]):\n",
    "    \"\"\"Create a representative sample with AFSCs from desired categories only\"\"\"\n",
    "    \n",
    "    sample_data = {\n",
    "        \"metadata\": data[\"metadata\"],\n",
    "        \"afscCategories\": []\n",
    "    }\n",
    "    \n",
    "    # If llm_optimized_structure exists, use that instead\n",
    "    if \"llm_optimized_structure\" in data:\n",
    "        print(\"Using the LLM-optimized structure as the base data\")\n",
    "        optimized_data = data[\"llm_optimized_structure\"]\n",
    "        \n",
    "        # Add the metadata\n",
    "        sample_data[\"metadata\"] = optimized_data[\"metadata\"]\n",
    "        sample_data[\"afscCategories\"] = []\n",
    "        \n",
    "        # Process each category, excluding specified ones\n",
    "        for category_name, category_data in optimized_data[\"afscCategories\"].items():\n",
    "            if category_name not in exclude_categories:\n",
    "                sample_category = {\n",
    "                    \"categoryName\": category_name,\n",
    "                    \"afscs\": []\n",
    "                }\n",
    "                \n",
    "                # Take a sample of AFSCs from each category\n",
    "                afsc_sample = category_data[\"afscs\"][:sample_size]\n",
    "                \n",
    "                # Add to the sample\n",
    "                sample_category[\"afscs\"] = afsc_sample\n",
    "                sample_data[\"afscCategories\"].append(sample_category)\n",
    "    else:\n",
    "        # Use the original structure\n",
    "        for category in data[\"afscCategories\"]:\n",
    "            if category[\"categoryName\"] not in exclude_categories:\n",
    "                sample_category = {\n",
    "                    \"categoryName\": category[\"categoryName\"],\n",
    "                    \"afscs\": []\n",
    "                }\n",
    "                \n",
    "                # Take a sample of AFSCs from each category\n",
    "                afsc_sample = category[\"afscs\"][:sample_size]\n",
    "                \n",
    "                # Add to the sample\n",
    "                sample_category[\"afscs\"] = afsc_sample\n",
    "                sample_data[\"afscCategories\"].append(sample_category)\n",
    "    \n",
    "    return sample_data\n",
    "\n",
    "# 3. Create a structured prompt for the LLM\n",
    "def create_taxonomy_prompt(sample_data):\n",
    "    \"\"\"Create a detailed prompt for the LLM to generate the taxonomy\"\"\"\n",
    "    \n",
    "    # Convert the sample data to a formatted JSON string\n",
    "    sample_json = json.dumps(sample_data, indent=2)\n",
    "    \n",
    "    # Build the prompt\n",
    "    prompt = f\"\"\"\n",
    "I have a dataset containing Air Force Specialty Codes (AFSCs) and their associated skills. I need you to create a comprehensive hierarchical taxonomy of military skills based on this data.\n",
    "\n",
    "Here is a representative sample of the dataset:\n",
    "\n",
    "```json\n",
    "{sample_json}\n",
    "```\n",
    "\n",
    "This is a portion of the dataset. The full dataset contains information for all Air Force Specialty Codes, organized by category (Officer and Enlisted), with each AFSC having associated skills and relevance scores.\n",
    "\n",
    "Please create a structured military skills taxonomy with the following requirements:\n",
    "\n",
    "1. STRUCTURE:\n",
    "   - Level 1: Major Skill Domains (6-8 broad categories like \"Technical Operations\", \"Leadership & Management\", etc.)\n",
    "   - Level 2: Skill Categories (subcategories within each domain)\n",
    "   - Level 3: Specific Skills (individual skills or competencies)\n",
    "   - Level 4: Specific Applications or Subskills (where appropriate)\n",
    "\n",
    "2. FORMAT:\n",
    "   - Present the taxonomy as a hierarchical outline\n",
    "   - Include clear headers for each level\n",
    "   - Cross-reference where appropriate to show relationships between skills across domains\n",
    "   - Include at least 8-10 specific skills per skill category for comprehensive coverage\n",
    "\n",
    "3. CONTENT REQUIREMENTS:\n",
    "   - Focus on action-oriented skills (verbs/capabilities)\n",
    "   - Prioritize skills with high relevance scores (70+) and \"high\" confidence\n",
    "   - Group similar skills together even if they use different terminology\n",
    "   - Emphasize military context and Air Force-specific applications\n",
    "   - Include appropriate skill level indicators (basic, intermediate, advanced) where appropriate\n",
    "   - Ensure coverage of both Officer and Enlisted skill requirements\n",
    "\n",
    "4. ADDITIONAL CONSIDERATIONS:\n",
    "   - This taxonomy will serve as a baseline for defining operational staff needs\n",
    "   - It should enhance resource allocation and training program development\n",
    "   - The taxonomy should be useful across different AFSCs and be scalable to other military services\n",
    "   - Include examples of how the taxonomy could be applied in practice (e.g., for training development)\n",
    "\n",
    "5. VISUALIZATION SUGGESTIONS:\n",
    "   - Provide suggestions for 3-4 visualization types that would effectively represent this taxonomy\n",
    "   - Include brief descriptions of how each visualization would help understand the taxonomy\n",
    "   - Suggest specific tools or approaches for implementing these visualizations\n",
    "\n",
    "Please format the taxonomy as follows:\n",
    "\n",
    "I. MAJOR SKILL DOMAIN\n",
    "   A. Skill Category\n",
    "      1. Specific Skill (relevant AFSCs: XXX, XXX)\n",
    "         - Subskill/Application\n",
    "         - Additional applications\n",
    "      2. Specific Skill\n",
    "   B. Skill Category\n",
    "\n",
    "II. MAJOR SKILL DOMAIN\n",
    "    ...\n",
    "\n",
    "For each skill, include:\n",
    "- Brief description\n",
    "- Primary associated verb(s)\n",
    "- Key AFSCs where this skill is most relevant\n",
    "- Confidence level (derived from the data)\n",
    "\n",
    "Please also provide a detailed explanation of your methodology and organizing principles for creating this taxonomy, including how this taxonomy could be further developed and applied in military contexts.\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# 4. Function to call Claude API (claude-3-5-sonnet-20240620)\n",
    "def call_claude_api(prompt, api_key, max_retries=3):\n",
    "    \"\"\"Call the Claude API with the specific model claude-3-5-sonnet-20240620\"\"\"\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"No Anthropic API key provided\")\n",
    "        return None\n",
    "    \n",
    "    # Use the verified working model\n",
    "    model = \"claude-3-5-sonnet-20240620\"\n",
    "    \n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"anthropic-version\": \"2023-06-01\"  # Required header\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Calling Claude API with {model} (attempt {attempt+1}/{max_retries})...\")\n",
    "            response = requests.post(\n",
    "                \"https://api.anthropic.com/v1/messages\",\n",
    "                headers=headers,\n",
    "                json=data\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                return result[\"content\"][0][\"text\"]\n",
    "            elif response.status_code == 529:  # Overloaded\n",
    "                print(\"Claude API is currently overloaded. Waiting before retry...\")\n",
    "                time.sleep(10 * (attempt + 1))  # Increasing backoff\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retrying in {5 * (attempt + 1)} seconds...\")\n",
    "                    time.sleep(5 * (attempt + 1))\n",
    "        except Exception as e:\n",
    "            print(f\"API call error: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {5 * (attempt + 1)} seconds...\")\n",
    "                time.sleep(5 * (attempt + 1))\n",
    "    \n",
    "    print(f\"Failed to call Claude API with model {model}. Check your API key and access.\")\n",
    "    return None\n",
    "\n",
    "# 5. Function to call OpenAI's models\n",
    "def call_openai_api(prompt, api_key, model=\"gpt-4-turbo\"):\n",
    "    \"\"\"Call the OpenAI API to generate the taxonomy\"\"\"\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"No OpenAI API key provided\")\n",
    "        return None\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 4000  # Reduced token limit\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Calling OpenAI API using {model}...\")\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=data\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 6. Save the generated taxonomy\n",
    "def save_taxonomy_output(output, model_name, output_dir):\n",
    "    \"\"\"Save the generated taxonomy to a file\"\"\"\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_path = os.path.join(output_dir, f\"military_skills_taxonomy_{model_name}_{timestamp}.txt\")\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(output)\n",
    "    \n",
    "    print(f\"Taxonomy saved to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# 7. Extract taxonomy data for manual submission\n",
    "def extract_data_for_manual_submission():\n",
    "    \"\"\"Extracts data and creates a prompt for manual submission to web interfaces\"\"\"\n",
    "    \n",
    "    # Load the data\n",
    "    data = load_taxonomy_data(ENHANCED_TAXONOMY_PATH)\n",
    "    \n",
    "    # Create a sample, excluding Warrant category\n",
    "    sample_data = create_representative_sample(data, sample_size=15, exclude_categories=[\"Warrant\"])\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = create_taxonomy_prompt(sample_data)\n",
    "    \n",
    "    # Save the prompt for manual submission\n",
    "    manual_path = os.path.join(OUTPUT_DIR, \"manual_submission_prompt.txt\")\n",
    "    with open(manual_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(prompt)\n",
    "    \n",
    "    print(f\"\\nPrompt for manual submission created and saved to: {manual_path}\")\n",
    "    print(\"You can copy this prompt and paste it directly into the Claude or ChatGPT web interface.\")\n",
    "    \n",
    "    return manual_path\n",
    "\n",
    "# Main execution - finalized version\n",
    "def generate_finalized_taxonomy():\n",
    "    # Step 1: Load the data\n",
    "    data = load_taxonomy_data(ENHANCED_TAXONOMY_PATH)\n",
    "    print(f\"Loaded data with {len(data['afscCategories'])} AFSC categories\")\n",
    "    \n",
    "    # Step 2: Create a sample with a more reasonable size (15 AFSCs per category), excluding Warrant\n",
    "    exclude_categories = [\"Warrant\"]\n",
    "    sample_size = 15  # Reduced from 25 to 15\n",
    "    sample_data = create_representative_sample(data, sample_size=sample_size, exclude_categories=exclude_categories)\n",
    "    \n",
    "    print(f\"Created enhanced sample without Warrant category ({len(sample_data['afscCategories'])} categories)\")\n",
    "    for category in sample_data['afscCategories']:\n",
    "        print(f\"  - {category['categoryName']}: {len(category['afscs'])} AFSCs\")\n",
    "    \n",
    "    # Step 3: Create the prompt\n",
    "    prompt = create_taxonomy_prompt(sample_data)\n",
    "    print(f\"Created prompt with {len(prompt)} characters\")\n",
    "    \n",
    "    # Optional: Save the prompt for reference\n",
    "    prompt_path = os.path.join(OUTPUT_DIR, \"enhanced_taxonomy_prompt.txt\")\n",
    "    with open(prompt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(prompt)\n",
    "    print(f\"Prompt saved to {prompt_path}\")\n",
    "    \n",
    "    # Step 4: Select API or manual approach\n",
    "    print(\"\\n===== GENERATION OPTIONS =====\")\n",
    "    print(\"1: Use API directly (requires API keys)\")\n",
    "    print(\"2: Create prompt for manual submission to web interfaces\")\n",
    "    approach = input(\"Select option (1 or 2): \").strip()\n",
    "    \n",
    "    if approach == \"2\":\n",
    "        # Manual approach - create the prompt file only\n",
    "        extract_data_for_manual_submission()\n",
    "        return \"Enhanced manual submission prompt generated. Please paste it into Claude or ChatGPT web interface.\"\n",
    "    \n",
    "    # API approach - get API keys directly\n",
    "    print(\"\\n===== API KEY INPUT =====\")\n",
    "    use_claude = input(\"Do you want to use Claude? (y/n): \").strip().lower() == 'y'\n",
    "    use_openai = input(\"Do you want to use OpenAI? (y/n): \").strip().lower() == 'y'\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 5: Call the selected APIs\n",
    "    if use_claude:\n",
    "        claude_key = input(\"Paste your Anthropic API key: \").strip()\n",
    "        claude_output = call_claude_api(prompt, claude_key)\n",
    "        if claude_output:\n",
    "            claude_path = save_taxonomy_output(claude_output, \"claude_3_5_sonnet\", OUTPUT_DIR)\n",
    "            print(f\"Claude taxonomy generated and saved to {claude_path}\")\n",
    "            results[\"claude\"] = claude_path\n",
    "    \n",
    "    if use_openai:\n",
    "        openai_key = input(\"Paste your OpenAI API key: \").strip()\n",
    "        model_options = {\n",
    "            \"1\": \"gpt-4-turbo\",\n",
    "            \"2\": \"gpt-4o\",\n",
    "            \"3\": \"gpt-3.5-turbo\"\n",
    "        }\n",
    "        model_choice = input(\"Which model? 1: gpt-4-turbo (recommended), 2: gpt-4o, 3: gpt-3.5-turbo (default: 1): \").strip() or \"1\"\n",
    "        model = model_options.get(model_choice, \"gpt-4-turbo\")\n",
    "        \n",
    "        openai_output = call_openai_api(prompt, openai_key, model)\n",
    "        if openai_output:\n",
    "            openai_path = save_taxonomy_output(openai_output, f\"{model.replace('-', '_')}_enhanced\", OUTPUT_DIR)\n",
    "            print(f\"Enhanced {model} taxonomy generated and saved to {openai_path}\")\n",
    "            results[\"openai\"] = openai_path\n",
    "    \n",
    "    # Step 6: Summary\n",
    "    print(\"\\nTaxonomy Generation Summary:\")\n",
    "    print(\"===========================\")\n",
    "    for model, path in results.items():\n",
    "        print(f\"✓ {model.upper()} taxonomy generated\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No taxonomies were generated. Please check API keys and try again.\")\n",
    "        print(\"Consider using the manual submission option instead.\")\n",
    "    \n",
    "    return \"Taxonomy generation process completed!\"\n",
    "\n",
    "# Run the finalized version directly\n",
    "if __name__ == \"__main__\":\n",
    "    generate_finalized_taxonomy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
