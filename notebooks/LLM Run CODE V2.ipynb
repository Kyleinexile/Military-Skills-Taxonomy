{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e37da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂  Loading enhanced taxonomy → C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\enhanced_military_skills_taxonomy.json\n",
      "✅  Loaded\n",
      "\n",
      "Generation route:\n",
      "1) Claude 3‑5 Sonnet   2) OpenAI GPT‑4‑Turbo / 4o   3) Manual only\n",
      "💾  Saved → C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\military_skills_taxonomy_gpt_4_turbo_pilot_20250422-084024.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you're reading this you'll have to change the paths to the files for your system. Additionally, you will need to add your API keys for Anthropic and OpenAI, but the code will prompt you for them.\n",
    "# This code is designed to be run in a Python 3 environment with the requests library installed.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  Air‑Force “Mega‑Skills”  →  Hierarchical Taxonomy Generator  (v 2.1)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "import json, os, pathlib, time, requests, textwrap\n",
    "\n",
    "# ╭──────────────────────────  PATHS  ─────────────────────────╮\n",
    "ENHANCED_TAXONOMY_PATH = pathlib.Path(\n",
    "    r\"C:\"\n",
    ")\n",
    "OUTPUT_DIR = pathlib.Path(\n",
    "    r\"C:\"\n",
    ")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ╭──────────────────────  CONFIG KNOBS  ──────────────────────╮\n",
    "DEFAULT_SAMPLE_SIZE     = 24           # AFSCs per category\n",
    "EXCLUDE_CATEGORIES      = [\"Warrant\"]  # omit Warrant officers in pilot\n",
    "CLAUDE_MODEL            = \"claude-3-5-sonnet-20240620\"\n",
    "OPENAI_DEFAULT_MODEL    = \"gpt-4-turbo\"\n",
    "MAX_TOKENS              = 4000\n",
    "\n",
    "# ╭────────────────────────  HELPERS  ─────────────────────────╮\n",
    "def load_taxonomy(path: pathlib.Path) -> dict:\n",
    "    print(f\"📂  Loading enhanced taxonomy → {path}\")\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"✅  Loaded\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_sample(data: dict,\n",
    "                  sample_size: int = DEFAULT_SAMPLE_SIZE,\n",
    "                  exclude: list[str] = EXCLUDE_CATEGORIES) -> dict:\n",
    "    \"\"\"Return lightweight sample: {metadata, afscCategories:[…]}\"\"\"\n",
    "    src = data.get(\"llm_optimized_structure\", data)\n",
    "    out = {\"metadata\": src[\"metadata\"], \"afscCategories\": []}\n",
    "\n",
    "    # src[\"afscCategories\"] may be list OR dict ― handle both\n",
    "    cats = (\n",
    "        src[\"afscCategories\"].items()\n",
    "        if isinstance(src[\"afscCategories\"], dict)\n",
    "        else ((c[\"categoryName\"], c) for c in src[\"afscCategories\"])\n",
    "    )\n",
    "\n",
    "    for name, cat in cats:\n",
    "        if name in exclude:\n",
    "            continue\n",
    "        out[\"afscCategories\"].append(\n",
    "            {\"categoryName\": name, \"afscs\": cat[\"afscs\"][:sample_size]}\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "# ── 3.  Build LLM prompt ────────────────────────────────────\n",
    "def build_prompt(sample: dict) -> str:\n",
    "    sample_json = json.dumps(sample, indent=2)\n",
    "    prompt = f\"\"\"\n",
    "    I have a dataset containing Air‑Force Specialty Codes (AFSCs) and their\n",
    "    associated skills. Create a comprehensive hierarchical taxonomy of\n",
    "    *military* skills from this data.\n",
    "\n",
    "    ▼ Representative sample (JSON)\n",
    "    ```json\n",
    "    {sample_json}\n",
    "    ```\n",
    "\n",
    "    REQUIREMENTS\n",
    "    1. STRUCTURE\n",
    "       • Level 1 – Major Domains (6‑8)            • Level 3 – Specific Skills\n",
    "       • Level 2 – Skill Categories               • Level 4 – Sub‑skills (if useful)\n",
    "\n",
    "    2. FORMAT\n",
    "       • Roman I., A., 1., a. outline\n",
    "       • Show relevant AFSCs in parentheses        • 8‑10 skills per category\n",
    "\n",
    "    3. CONTENT\n",
    "       • Verb‑based, action‑oriented skills\n",
    "       • Prefer high‑relevance / high‑confidence (≥ 70)\n",
    "       • Group synonyms; keep military context\n",
    "\n",
    "    4. EXTRAS\n",
    "       • Brief description + main verb for each skill\n",
    "       • 3‑4 visualisation ideas (bullet list)\n",
    "       • ≤ 120‑word methodology paragraph\n",
    "\n",
    "    OUTPUT EXAMPLE\n",
    "    I.  MAJOR DOMAIN\n",
    "        A. Skill Category\n",
    "           1. Specific skill (AFSCs: 1A111, 1A211)\n",
    "              – sub‑skill / application\n",
    "           2. …\n",
    "\n",
    "    Keep the outline concise; max depth = 4 levels.\n",
    "    \"\"\"\n",
    "    return textwrap.dedent(prompt)\n",
    "\n",
    "\n",
    "# ── 4.  API CALLS ───────────────────────────────────────────\n",
    "def call_claude(prompt: str, api_key: str, retries: int = 3) -> str | None:\n",
    "    if not api_key:\n",
    "        print(\"🔑  No Anthropic key provided.\"); return None\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"anthropic-version\": \"2023-06-01\"\n",
    "    }\n",
    "    payload = {\"model\": CLAUDE_MODEL, \"max_tokens\": MAX_TOKENS,\n",
    "               \"messages\": [{\"role\":\"user\",\"content\": prompt}]}\n",
    "    for i in range(retries):\n",
    "        r = requests.post(\"https://api.anthropic.com/v1/messages\",\n",
    "                          headers=headers, json=payload, timeout=60)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()[\"content\"][0][\"text\"]\n",
    "        print(f\"Claude error {r.status_code}; retry {i+1}/{retries}\")\n",
    "        time.sleep(5*(i+1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def call_openai(prompt: str, api_key: str, model: str) -> str | None:\n",
    "    if not api_key:\n",
    "        print(\"🔑  No OpenAI key provided.\"); return None\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": model, \"messages\": [{\"role\":\"user\",\"content\": prompt}],\n",
    "               \"max_tokens\": MAX_TOKENS}\n",
    "    r = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
    "                      headers=headers, json=payload, timeout=60)\n",
    "    if r.status_code == 200:\n",
    "        return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"OpenAI error\", r.status_code, r.text[:300])\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_output(txt: str, tag: str) -> pathlib.Path:\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    p  = OUTPUT_DIR / f\"military_skills_taxonomy_{tag}_{ts}.txt\"\n",
    "    p.write_text(txt, encoding=\"utf-8\")\n",
    "    print(\"💾  Saved →\", p); return p\n",
    "\n",
    "\n",
    "# ── 5.  DRIVER ──────────────────────────────────────────────\n",
    "def main():\n",
    "    data = load_taxonomy(ENHANCED_TAXONOMY_PATH)\n",
    "    sample = create_sample(data)\n",
    "    prompt = build_prompt(sample)\n",
    "    (OUTPUT_DIR/\"prompt_for_reference.txt\").write_text(prompt, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nGeneration route:\")\n",
    "    print(\"1) Claude 3‑5 Sonnet   2) OpenAI GPT‑4‑Turbo / 4o   3) Manual only\")\n",
    "    choice = input(\"Select (1/2/3): \").strip()\n",
    "\n",
    "    if choice == \"3\":\n",
    "        print(\"Prompt saved; paste into web UI as required.\"); return\n",
    "\n",
    "    if choice == \"1\":\n",
    "        claude_key = input(\"Paste Anthropic API key: \").strip()\n",
    "        out = call_claude(prompt, claude_key)\n",
    "        if out: save_output(out, \"claude_3_5_sonnet_pilot\")\n",
    "\n",
    "    if choice == \"2\":\n",
    "        openai_key = input(\"Paste OpenAI key: \").strip()\n",
    "        mdl = input(\"Model (gpt-4-turbo / gpt-4o) [default turbo]: \").strip() or OPENAI_DEFAULT_MODEL\n",
    "        out = call_openai(prompt, openai_key, mdl)\n",
    "        if out: save_output(out, mdl.replace(\"-\",\"_\")+\"_pilot\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laiser_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
