{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e37da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚  Loading enhanced taxonomy â†’ C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\enhanced_military_skills_taxonomy.json\n",
      "âœ…  Loaded\n",
      "\n",
      "Generation route:\n",
      "1) Claude 3â€‘5 Sonnet   2) OpenAI GPTâ€‘4â€‘Turbo / 4o   3) Manual only\n",
      "ðŸ’¾  Saved â†’ C:\\Users\\Kyle\\Desktop\\Grad School\\IS Demo\\Phase 2 Rebuild\\military_skills_taxonomy_gpt_4_turbo_pilot_20250422-084024.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you're reading this you'll have to change the paths to the files for your system. Additionally, you will need to add your API keys for Anthropic and OpenAI, but the code will prompt you for them.\n",
    "# This code is designed to be run in a Python 3 environment with the requests library installed.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Airâ€‘Force â€œMegaâ€‘Skillsâ€  â†’  Hierarchical Taxonomy Generator  (vÂ 2.1)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import json, os, pathlib, time, requests, textwrap\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  PATHS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "ENHANCED_TAXONOMY_PATH = pathlib.Path(\n",
    "    r\"C:\"\n",
    ")\n",
    "OUTPUT_DIR = pathlib.Path(\n",
    "    r\"C:\"\n",
    ")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  CONFIG KNOBS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "DEFAULT_SAMPLE_SIZE     = 24           # AFSCs per category\n",
    "EXCLUDE_CATEGORIES      = [\"Warrant\"]  # omit Warrant officers in pilot\n",
    "CLAUDE_MODEL            = \"claude-3-5-sonnet-20240620\"\n",
    "OPENAI_DEFAULT_MODEL    = \"gpt-4-turbo\"\n",
    "MAX_TOKENS              = 4000\n",
    "\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  HELPERS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "def load_taxonomy(path: pathlib.Path) -> dict:\n",
    "    print(f\"ðŸ“‚  Loading enhanced taxonomy â†’ {path}\")\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"âœ…  Loaded\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_sample(data: dict,\n",
    "                  sample_size: int = DEFAULT_SAMPLE_SIZE,\n",
    "                  exclude: list[str] = EXCLUDE_CATEGORIES) -> dict:\n",
    "    \"\"\"Return lightweight sample: {metadata, afscCategories:[â€¦]}\"\"\"\n",
    "    src = data.get(\"llm_optimized_structure\", data)\n",
    "    out = {\"metadata\": src[\"metadata\"], \"afscCategories\": []}\n",
    "\n",
    "    # src[\"afscCategories\"] may be list OR dict â€• handle both\n",
    "    cats = (\n",
    "        src[\"afscCategories\"].items()\n",
    "        if isinstance(src[\"afscCategories\"], dict)\n",
    "        else ((c[\"categoryName\"], c) for c in src[\"afscCategories\"])\n",
    "    )\n",
    "\n",
    "    for name, cat in cats:\n",
    "        if name in exclude:\n",
    "            continue\n",
    "        out[\"afscCategories\"].append(\n",
    "            {\"categoryName\": name, \"afscs\": cat[\"afscs\"][:sample_size]}\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "# â”€â”€ 3.  Build LLM prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_prompt(sample: dict) -> str:\n",
    "    sample_json = json.dumps(sample, indent=2)\n",
    "    prompt = f\"\"\"\n",
    "    I have a dataset containing Airâ€‘Force Specialty Codes (AFSCs) and their\n",
    "    associated skills. Create a comprehensive hierarchical taxonomy of\n",
    "    *military* skills from this data.\n",
    "\n",
    "    â–¼ Representative sample (JSON)\n",
    "    ```json\n",
    "    {sample_json}\n",
    "    ```\n",
    "\n",
    "    REQUIREMENTS\n",
    "    1. STRUCTURE\n",
    "       â€¢ LevelÂ 1Â â€“Â Major Domains (6â€‘8)            â€¢ LevelÂ 3Â â€“Â Specific Skills\n",
    "       â€¢ LevelÂ 2Â â€“Â Skill Categories               â€¢ LevelÂ 4Â â€“Â Subâ€‘skills (if useful)\n",
    "\n",
    "    2. FORMAT\n",
    "       â€¢ RomanÂ I., A., 1., a. outline\n",
    "       â€¢ Show relevant AFSCs in parentheses        â€¢ 8â€‘10 skills per category\n",
    "\n",
    "    3. CONTENT\n",
    "       â€¢ Verbâ€‘based, actionâ€‘oriented skills\n",
    "       â€¢ Prefer highâ€‘relevance / highâ€‘confidence (â‰¥Â 70)\n",
    "       â€¢ Group synonyms; keep military context\n",
    "\n",
    "    4. EXTRAS\n",
    "       â€¢ Brief description + main verb for each skill\n",
    "       â€¢ 3â€‘4 visualisation ideas (bullet list)\n",
    "       â€¢ â‰¤Â 120â€‘word methodology paragraph\n",
    "\n",
    "    OUTPUT EXAMPLE\n",
    "    I.  MAJOR DOMAIN\n",
    "        A. Skill Category\n",
    "           1. Specific skill (AFSCs: 1A111,Â 1A211)\n",
    "              â€“ subâ€‘skill / application\n",
    "           2. â€¦\n",
    "\n",
    "    Keep the outline concise; max depthÂ =Â 4 levels.\n",
    "    \"\"\"\n",
    "    return textwrap.dedent(prompt)\n",
    "\n",
    "\n",
    "# â”€â”€ 4.  API CALLS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def call_claude(prompt: str, api_key: str, retries: int = 3) -> str | None:\n",
    "    if not api_key:\n",
    "        print(\"ðŸ”‘  No Anthropic key provided.\"); return None\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"anthropic-version\": \"2023-06-01\"\n",
    "    }\n",
    "    payload = {\"model\": CLAUDE_MODEL, \"max_tokens\": MAX_TOKENS,\n",
    "               \"messages\": [{\"role\":\"user\",\"content\": prompt}]}\n",
    "    for i in range(retries):\n",
    "        r = requests.post(\"https://api.anthropic.com/v1/messages\",\n",
    "                          headers=headers, json=payload, timeout=60)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()[\"content\"][0][\"text\"]\n",
    "        print(f\"Claude error {r.status_code}; retry {i+1}/{retries}\")\n",
    "        time.sleep(5*(i+1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def call_openai(prompt: str, api_key: str, model: str) -> str | None:\n",
    "    if not api_key:\n",
    "        print(\"ðŸ”‘  No OpenAI key provided.\"); return None\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": model, \"messages\": [{\"role\":\"user\",\"content\": prompt}],\n",
    "               \"max_tokens\": MAX_TOKENS}\n",
    "    r = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
    "                      headers=headers, json=payload, timeout=60)\n",
    "    if r.status_code == 200:\n",
    "        return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"OpenAI error\", r.status_code, r.text[:300])\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_output(txt: str, tag: str) -> pathlib.Path:\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    p  = OUTPUT_DIR / f\"military_skills_taxonomy_{tag}_{ts}.txt\"\n",
    "    p.write_text(txt, encoding=\"utf-8\")\n",
    "    print(\"ðŸ’¾  Saved â†’\", p); return p\n",
    "\n",
    "\n",
    "# â”€â”€ 5.  DRIVER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def main():\n",
    "    data = load_taxonomy(ENHANCED_TAXONOMY_PATH)\n",
    "    sample = create_sample(data)\n",
    "    prompt = build_prompt(sample)\n",
    "    (OUTPUT_DIR/\"prompt_for_reference.txt\").write_text(prompt, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nGeneration route:\")\n",
    "    print(\"1) Claude 3â€‘5 Sonnet   2) OpenAI GPTâ€‘4â€‘Turbo / 4o   3) Manual only\")\n",
    "    choice = input(\"Select (1/2/3): \").strip()\n",
    "\n",
    "    if choice == \"3\":\n",
    "        print(\"Prompt saved; paste into web UI as required.\"); return\n",
    "\n",
    "    if choice == \"1\":\n",
    "        claude_key = input(\"Paste Anthropic API key: \").strip()\n",
    "        out = call_claude(prompt, claude_key)\n",
    "        if out: save_output(out, \"claude_3_5_sonnet_pilot\")\n",
    "\n",
    "    if choice == \"2\":\n",
    "        openai_key = input(\"Paste OpenAI key: \").strip()\n",
    "        mdl = input(\"Model (gpt-4-turbo / gpt-4o) [default turbo]: \").strip() or OPENAI_DEFAULT_MODEL\n",
    "        out = call_openai(prompt, openai_key, mdl)\n",
    "        if out: save_output(out, mdl.replace(\"-\",\"_\")+\"_pilot\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laiser_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
